#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€å°å¯è¿è¡Œæµ‹è¯• - éªŒè¯å‚æ•°åŒ–Agentçš„æ ¸å¿ƒåŠŸèƒ½

è¿™ä¸ªè„šæœ¬ä¸éœ€è¦å®Œæ•´çš„è½¨è¿¹æˆ–orchestratorï¼Œ
åªæµ‹è¯•æ ¸å¿ƒçš„å‚æ•°å­¦ä¹ åŠŸèƒ½ã€‚
"""

import sys
import numpy as np

# è§£å†³Windowsç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
from tau2.continual_learning.agents.parametric.tool_scorer import ToolScorer
from tau2.continual_learning.agents.parametric.parametric_memory import ParametricMemory
from tau2.environment.tool import Tool

print("=" * 80)
print("å‚æ•°åŒ–æŒç»­å­¦ä¹  - æœ€å°æµ‹è¯•")
print("=" * 80)

# ============================================================================
# 1. æµ‹è¯•Tool Scorerï¼ˆæ ¸å¿ƒå¯å­¦ä¹ ç»„ä»¶ï¼‰
# ============================================================================

print("\nã€æµ‹è¯•1: Tool Scorer - å¯å­¦ä¹ å·¥å…·é€‰æ‹©ã€‘")
print("-" * 80)

# å®šä¹‰å·¥å…·
def search(query: str) -> str:
    """æœç´¢å·¥å…·"""
    return f"Found: {query}"

def email(to: str, subject: str) -> str:
    """é‚®ä»¶å·¥å…·"""
    return f"Email to {to}"

tools = [Tool(search), Tool(email)]

# åˆ›å»ºTool Scorer
scorer = ToolScorer(
    tools=tools,
    embedding_dim=768,
    learning_rate=0.01,
)

print(f"âœ“ åˆ›å»ºToolScoreræˆåŠŸ")
print(f"  - å·¥å…·æ•°é‡: {len(tools)}")
print(f"  - å‚æ•°shape: {scorer.weights.shape}")
print(f"  - æ€»å‚æ•°é‡: {scorer.weights.size}")

# æµ‹è¯•å·¥å…·è¯„åˆ†
print("\n1.1 æµ‹è¯•å·¥å…·è¯„åˆ†ï¼ˆåˆå§‹çŠ¶æ€ï¼‰:")
state_emb = np.random.randn(768)
scores = scorer.score_tools(state_emb)
print(f"  å·¥å…·åˆ†æ•°: {scores}")

probs = scorer.get_tool_probabilities(state_emb)
print(f"  å·¥å…·æ¦‚ç‡: {probs}")

# æµ‹è¯•å‚æ•°æ›´æ–°
print("\n1.2 æµ‹è¯•å‚æ•°æ›´æ–°:")
old_weights = scorer.weights.copy()

update_stats = scorer.update_weights(
    state_embedding=state_emb,
    selected_tool="search",
    reward=1.0,
    success=True,
)

print(f"  âœ“ æ›´æ–°æˆåŠŸ: {update_stats['updated']}")
print(f"  - å·¥å…·: {update_stats['tool']}")
print(f"  - æ¦‚ç‡: {update_stats['probability']:.4f}")
print(f"  - æ¢¯åº¦èŒƒæ•°: {update_stats['gradient_norm']:.6f}")

# éªŒè¯å‚æ•°ç¡®å®å˜åŒ–äº†
param_change = np.linalg.norm(scorer.weights - old_weights)
print(f"  - å‚æ•°å˜åŒ–é‡: {param_change:.6f}")

if param_change > 0:
    print(f"  âœ“ å‚æ•°ç¡®å®æ›´æ–°äº†ï¼è¿™æ˜¯çœŸæ­£çš„å­¦ä¹ ï¼")
else:
    print(f"  âœ— å‚æ•°æ²¡æœ‰å˜åŒ–")

# ============================================================================
# 2. æµ‹è¯•Parametric Memoryï¼ˆå¯å­¦ä¹ è®°å¿†ï¼‰
# ============================================================================

print("\nã€æµ‹è¯•2: Parametric Memory - å¯å­¦ä¹ è®°å¿†é‡è¦æ€§ã€‘")
print("-" * 80)

# åˆ›å»ºParametric Memory
memory = ParametricMemory(
    max_size=100,
    embedding_dim=768,
    learning_rate=0.01,
    initial_importance=1.0,
)

print(f"âœ“ åˆ›å»ºParametricMemoryæˆåŠŸ")
print(f"  - æœ€å¤§å®¹é‡: {memory.max_size}")
print(f"  - å½“å‰å¤§å°: {len(memory)}")

# æ·»åŠ ä¸€äº›ç»éªŒ
print("\n2.1 æ·»åŠ ç»éªŒ:")
from tau2.continual_learning.memory.buffer import Experience
from datetime import datetime

for i in range(5):
    exp = Experience(
        experience_id=f"exp_{i}",
        task_id=f"task_{i}",
        domain="test",
        timestamp=datetime.now(),
        observation=f"è§‚å¯Ÿ {i}",
        action=f"åŠ¨ä½œ {i}",
        reward=0.5 + i * 0.1,
        success=True,
        embedding=list(np.random.randn(768)),
    )
    memory.add(exp)

print(f"  âœ“ æ·»åŠ äº† {len(memory)} æ¡ç»éªŒ")

# æŸ¥çœ‹é‡è¦æ€§æƒé‡
print("\n2.2 æŸ¥çœ‹åˆå§‹é‡è¦æ€§æƒé‡:")
for exp in list(memory)[:3]:
    importance = memory.get_importance(exp.experience_id)
    print(f"  - {exp.experience_id}: importance={importance:.3f}, reward={exp.reward:.3f}")

# æ›´æ–°é‡è¦æ€§
print("\n2.3 æ›´æ–°é‡è¦æ€§æƒé‡:")
exp_id = list(memory)[0].experience_id
old_importance = memory.get_importance(exp_id)

update_info = memory.update_importance(exp_id, gradient=0.5)

new_importance = memory.get_importance(exp_id)
print(f"  âœ“ é‡è¦æ€§æ›´æ–°æˆåŠŸ")
print(f"  - ç»éªŒID: {exp_id}")
print(f"  - æ—§é‡è¦æ€§: {old_importance:.3f}")
print(f"  - æ–°é‡è¦æ€§: {new_importance:.3f}")
print(f"  - å˜åŒ–: {new_importance - old_importance:.3f}")

if abs(new_importance - old_importance) > 0.001:
    print(f"  âœ“ é‡è¦æ€§ç¡®å®å˜åŒ–äº†ï¼è®°å¿†åœ¨å­¦ä¹ ï¼")
else:
    print(f"  âœ— é‡è¦æ€§æ²¡æœ‰å˜åŒ–")

# åŸºäºé‡è¦æ€§é‡‡æ ·
print("\n2.4 åŸºäºé‡è¦æ€§é‡‡æ ·:")
sampled = memory.sample_by_importance(n=3)
print(f"  âœ“ é‡‡æ ·äº† {len(sampled)} æ¡ç»éªŒ")
for exp in sampled:
    importance = memory.get_importance(exp.experience_id)
    print(f"  - {exp.experience_id}: importance={importance:.3f}")

# ============================================================================
# 3. æµ‹è¯•EWCçš„Fisher Information
# ============================================================================

print("\nã€æµ‹è¯•3: EWC - Fisher Informationè®¡ç®—ã€‘")
print("-" * 80)

# å‡†å¤‡æ•°æ®
print("\n3.1 å‡†å¤‡è®­ç»ƒæ•°æ®:")
state_embeddings = [np.random.randn(768) for _ in range(20)]
selected_tools = ["search"] * 10 + ["email"] * 10

print(f"  - çŠ¶æ€æ•°: {len(state_embeddings)}")
print(f"  - å·¥å…·é€‰æ‹©: {selected_tools[:5]}...")

# è®¡ç®—Fisher
print("\n3.2 è®¡ç®—Fisher Information:")
fisher = scorer.compute_fisher_information(
    state_embeddings=state_embeddings,
    selected_tools=selected_tools,
)

print(f"  âœ“ Fisherè®¡ç®—æˆåŠŸ")
print(f"  - Fisher shape: {fisher.shape}")
print(f"  - Fisherå‡å€¼: {fisher.mean():.6f}")
print(f"  - Fisheræœ€å¤§å€¼: {fisher.max():.6f}")
print(f"  - Fisheréé›¶å…ƒç´ : {np.count_nonzero(fisher)}")

# æŸ¥çœ‹é‡è¦å‚æ•°
important_params = np.sum(fisher > 0.01)
print(f"  - é‡è¦å‚æ•°æ•° (F>0.01): {important_params}")

# æµ‹è¯•EWCæ­£åˆ™åŒ–
print("\n3.3 æµ‹è¯•EWCæ­£åˆ™åŒ–:")
ewc_loss = scorer.get_ewc_regularization_loss(ewc_lambda=1.0)
print(f"  - EWC loss: {ewc_loss:.6f}")

if ewc_loss > 0:
    print(f"  âœ“ EWCæ­£åˆ™åŒ–ç”Ÿæ•ˆï¼")
else:
    print(f"  - EWC lossä¸º0ï¼ˆæ­£å¸¸ï¼Œå‚æ•°æœªåç¦»ï¼‰")

# ============================================================================
# 4. æ€»ç»“
# ============================================================================

print("\n" + "=" * 80)
print("ã€æµ‹è¯•æ€»ç»“ã€‘")
print("=" * 80)

print("\nâœ… æ ¸å¿ƒåŠŸèƒ½éªŒè¯:")
print("  1. âœ“ Tool Scorerå¯ä»¥å­¦ä¹ å’Œæ›´æ–°å‚æ•°")
print("  2. âœ“ Parametric Memoryå¯ä»¥å­¦ä¹ è®°å¿†é‡è¦æ€§")
print("  3. âœ“ Fisher Informationå¯ä»¥è®¡ç®—å’Œç”¨äºEWC")
print("  4. âœ“ è¿™äº›éƒ½æ˜¯çœŸæ­£çš„å‚æ•°å­¦ä¹ ï¼Œä¸æ˜¯promptå·¥ç¨‹")

print("\nğŸ’¡ å…³é”®å¯¹æ¯”:")
print("  ICL-ER (æ—§):  å‚æ•°é‡=0, åªå­˜å‚¨ç»éªŒåˆ°prompt")
print("  Parametric (æ–°): å‚æ•°é‡=" + f"{scorer.weights.size}, çœŸæ­£çš„æ¢¯åº¦å­¦ä¹ ")

print("\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
print(f"  - Tool Scorerå‚æ•°: {scorer.weights.size}")
print(f"  - Memoryé‡è¦æ€§å‚æ•°: {len(memory)}")
print(f"  - æ€»å¯å­¦ä¹ å‚æ•°: {scorer.weights.size + len(memory)}")

print("\nğŸ“ ç†è®ºæ”¯æ’‘:")
print("  - Tool Scorer: åŸºäºREINFORCEçš„ç­–ç•¥æ¢¯åº¦")
print("  - EWC: Fisher Information Matrix (Kirkpatrick et al., 2017)")
print("  - Memory: å¯å­¦ä¹ é‡è¦æ€§æƒé‡")

print("\nğŸš€ ä¸‹ä¸€æ­¥:")
print("  - é›†æˆåˆ°å®Œæ•´çš„tau2å®éªŒä¸­")
print("  - è¿è¡Œå¤šä»»åŠ¡æŒç»­å­¦ä¹ å®éªŒ")
print("  - å¯¹æ¯”5ç§æ–¹æ³•çš„æ€§èƒ½")
print("  - è¯¦è§ HOWTO_RUN.md")

print("\nâœ¨ è¿™æ˜¯çœŸæ­£çš„æŒç»­å­¦ä¹ æ¡†æ¶ï¼")
print("=" * 80)
