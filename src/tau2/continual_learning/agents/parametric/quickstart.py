#!/usr/bin/env python3
"""
å¿«é€Ÿå¼€å§‹è„šæœ¬ - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å‚æ•°åŒ–æŒç»­å­¦ä¹ Agent

è¿™æ˜¯æœ€ç®€å•çš„ä¾‹å­ï¼Œå±•ç¤ºåŸºæœ¬ç”¨æ³•ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from tau2.environment.tool import Tool
from tau2.continual_learning.agents.parametric import (
    EWCContinualLearningAgent,
)
from tau2.data_model.message import (
    UserMessage,
    AssistantMessage,
    ToolCall,
    ToolMessage,
)


# ============================================================================
# 1. å®šä¹‰ç®€å•çš„å·¥å…·
# ============================================================================

def search_database(query: str) -> str:
    """æœç´¢å®¢æˆ·æ•°æ®åº“"""
    return f"æ‰¾åˆ°äº†å…³äº '{query}' çš„3æ¡ç»“æœ"


def send_email(to: str, subject: str) -> str:
    """å‘é€é‚®ä»¶ç»™å®¢æˆ·"""
    return f"é‚®ä»¶å·²å‘é€ç»™ {to}: {subject}"


# ============================================================================
# 2. åˆ›å»ºAgent
# ============================================================================

def main():
    print("=" * 80)
    print("å‚æ•°åŒ–æŒç»­å­¦ä¹  - å¿«é€Ÿå¼€å§‹")
    print("=" * 80)

    # åˆ›å»ºå·¥å…·
    tools = [
        Tool(search_database),
        Tool(send_email),
    ]

    # åˆ›å»ºdomain policy
    policy = """
ä½ æ˜¯ä¸€ä¸ªå®¢æœåŠ©æ‰‹ã€‚
å¯ä»¥æœç´¢æ•°æ®åº“å’Œå‘é€é‚®ä»¶ã€‚
è¦å‹å¥½å’Œä¸“ä¸šã€‚
    """.strip()

    # åˆ›å»ºEWC Agent
    print("\n1. åˆ›å»ºEWC Agent...")
    agent = EWCContinualLearningAgent(
        tools=tools,
        domain_policy=policy,
        llm="gpt-4",
        embedding_dim=768,
        learning_rate=0.01,
        ewc_lambda=1.0,
        online_ewc=True,
    )
    print(f"   âœ“ Agentåˆ›å»ºæˆåŠŸ: {agent.__class__.__name__}")

    # ============================================================================
    # 3. æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„ä»»åŠ¡
    # ============================================================================

    print("\n2. æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ...")

    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿè½¨è¿¹
    trajectory = [
        UserMessage(role="user", content="æˆ‘æƒ³æŸ¥è¯¢è®¢å• #12345"),
        AssistantMessage(
            role="assistant",
            content=None,
            tool_calls=[
                ToolCall(
                    id="call_1",
                    name="search_database",
                    arguments={"query": "è®¢å• #12345"}
                )
            ]
        ),
        ToolMessage(
            role="tool",
            tool_call_id="call_1",
            content="æ‰¾åˆ°äº†å…³äº 'è®¢å• #12345' çš„3æ¡ç»“æœ"
        ),
        AssistantMessage(
            role="assistant",
            content="æˆ‘æ‰¾åˆ°äº†æ‚¨çš„è®¢å• #12345ï¼ŒçŠ¶æ€æ˜¯å¾…å¤„ç†ã€‚"
        ),
    ]

    print(f"   âœ“ åˆ›å»ºäº†åŒ…å« {len(trajectory)} æ¡æ¶ˆæ¯çš„è½¨è¿¹")

    # ============================================================================
    # 4. Agentå­¦ä¹ ï¼ˆå…³é”®æ­¥éª¤ï¼ï¼‰
    # ============================================================================

    print("\n3. Agentä»è½¨è¿¹ä¸­å­¦ä¹ ...")

    learning_stats = agent.learn_from_trajectory(
        task_id="task_001",
        domain="customer_service",
        trajectory=trajectory,
        reward=1.0,  # ä»»åŠ¡æˆåŠŸ
        success=True,
    )

    print(f"   âœ“ å­¦ä¹ å®Œæˆ!")
    print(f"   - å‚æ•°æ›´æ–°æ¬¡æ•°: {learning_stats.get('parameter_updates', 0)}")
    print(f"   - ç»éªŒæ·»åŠ æ•°: {learning_stats.get('experiences_added', 0)}")

    if 'fisher_computation' in learning_stats:
        fisher_stats = learning_stats['fisher_computation']
        if fisher_stats.get('computed'):
            print(f"   - Fisher Informationå·²è®¡ç®— (æ ·æœ¬æ•°: {fisher_stats.get('num_samples', 0)})")

    # ============================================================================
    # 5. æŸ¥çœ‹Agentç»Ÿè®¡
    # ============================================================================

    print("\n4. Agentç»Ÿè®¡ä¿¡æ¯:")
    stats = agent.get_statistics()

    print(f"   - å®Œæˆä»»åŠ¡æ•°: {stats['tasks_completed']}")
    print(f"   - æ€»æ­¥éª¤æ•°: {stats['total_steps']}")
    print(f"   - å­¦ä¹ çš„ä»»åŠ¡æ•°: {stats.get('num_tasks_learned', 0)}")
    print(f"   - å½“å‰Î»å€¼: {stats.get('current_lambda', 0):.3f}")

    # Tool Scorerç»Ÿè®¡
    if 'tool_scorer_stats' in stats:
        ts_stats = stats['tool_scorer_stats']
        print(f"\n   Tool Scorer:")
        print(f"   - æ€»æ›´æ–°æ¬¡æ•°: {ts_stats['total_updates']}")
        print(f"   - æƒé‡èŒƒæ•°: {ts_stats['weights_norm']:.4f}")
        print(f"   - å·¥å…·é€‰æ‹©æ¬¡æ•°: {ts_stats['tool_selection_counts']}")

    # Memoryç»Ÿè®¡
    if 'memory_buffer_stats' in stats:
        mem_stats = stats['memory_buffer_stats']
        print(f"\n   Memory Buffer:")
        print(f"   - ç»éªŒæ€»æ•°: {mem_stats['total_experiences']}")
        print(f"   - å¹³å‡å¥–åŠ±: {mem_stats['avg_reward']:.3f}")

    # ============================================================================
    # 6. å†å­¦ä¹ å‡ ä¸ªä»»åŠ¡
    # ============================================================================

    print("\n5. ç»§ç»­å­¦ä¹ æ›´å¤šä»»åŠ¡...")

    for i in range(2, 4):
        # åˆ›å»ºæ–°è½¨è¿¹
        new_trajectory = [
            UserMessage(role="user", content=f"æˆ‘éœ€è¦å¸®åŠ©å¤„ç†é—®é¢˜ #{i}"),
            AssistantMessage(
                role="assistant",
                content=None,
                tool_calls=[
                    ToolCall(
                        id=f"call_{i}",
                        name="search_database",
                        arguments={"query": f"é—®é¢˜ #{i}"}
                    )
                ]
            ),
            ToolMessage(
                role="tool",
                tool_call_id=f"call_{i}",
                content=f"æ‰¾åˆ°äº†å…³äº 'é—®é¢˜ #{i}' çš„3æ¡ç»“æœ"
            ),
            AssistantMessage(
                role="assistant",
                content=f"æˆ‘å·²ç»æ‰¾åˆ°äº†é—®é¢˜ #{i} çš„ä¿¡æ¯ã€‚"
            ),
        ]

        stats = agent.learn_from_trajectory(
            task_id=f"task_{i:03d}",
            domain="customer_service",
            trajectory=new_trajectory,
            reward=1.0,
            success=True,
        )

        print(f"   âœ“ Task {i}: å‚æ•°æ›´æ–° {stats.get('parameter_updates', 0)} æ¬¡")

    # ============================================================================
    # 7. æœ€ç»ˆç»Ÿè®¡
    # ============================================================================

    print("\n6. æœ€ç»ˆç»Ÿè®¡:")
    final_stats = agent.get_statistics()

    print(f"   - æ€»å®Œæˆä»»åŠ¡: {final_stats['tasks_completed']}")
    print(f"   - å­¦ä¹ ä»»åŠ¡æ•°: {final_stats.get('num_tasks_learned', 0)}")

    if 'cumulative_fisher_stats' in final_stats:
        fisher_stats = final_stats['cumulative_fisher_stats']
        print(f"\n   Fisher Information (ç´¯ç§¯):")
        print(f"   - å¹³å‡å€¼: {fisher_stats['mean']:.6f}")
        print(f"   - é‡è¦å‚æ•°æ•°: {fisher_stats['num_important']}")

    print("\n" + "=" * 80)
    print("âœ“ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)

    print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
    print("  1. Agentæœ‰å¯å­¦ä¹ çš„å‚æ•°ï¼ˆTool Scoreræƒé‡ w_iï¼‰")
    print("  2. æ¯æ¬¡learn_from_trajectoryéƒ½ä¼šæ›´æ–°å‚æ•°")
    print("  3. Fisher Informationä¿æŠ¤é‡è¦å‚æ•°é˜²æ­¢é—å¿˜")
    print("  4. è¿™æ˜¯çœŸæ­£çš„æŒç»­å­¦ä¹ ï¼Œä¸åªæ˜¯prompt engineeringï¼")

    print("\nğŸ“– ä¸‹ä¸€æ­¥:")
    print("  - æŸ¥çœ‹ README.md äº†è§£å®Œæ•´åŠŸèƒ½")
    print("  - è¿è¡Œ example_usage.py æŸ¥çœ‹æ›´å¤šç¤ºä¾‹")
    print("  - å°è¯•å…¶ä»–æ–¹æ³•: Replay, Parameter Isolation, Progressive, Meta-CL")


if __name__ == "__main__":
    main()
